# -*- coding: utf-8 -*-
"""#TUTOR_PRE-PROCESSING_DATA_X(TWITTER.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/17B91jBvsNtM5mr9nD-LxO4u5CVZxA34F

# ***MEMBACA DATASET HASIL CRAWLING KEYWORD TIKTOKSHOP***
"""

import pandas as pd

data = pd.read_csv("DatasetKeyTikTokShop.csv", sep=";")
data.head(2)

"""# ***CEK INFORMASI DATASET***"""

data.info()

"""# **STATISTIK DATASET**"""

summary = data.describe()
summary.head()

"""# ***VIS ORIGINAL DATA WORDCLOUD & FREKUENSI KATA***

**Wordcloud**

---
"""

import pandas as pd
import numpy as np
from PIL import Image
from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator
import matplotlib.pyplot as plt

df = ' '.join(data['full_text'].tolist())

stopwords = set(STOPWORDS)
stopwords.update(['https', 'co', 'RT', '...', 'amp'])

wc = WordCloud(stopwords=stopwords, background_color="black", max_words=500, width=800, height=400)
wc.generate(df)

plt.figure(figsize=(10, 5))
plt.imshow(wc, interpolation='bilinear')
plt.axis("off")
plt.show()

"""**Menghitung Frekuensi Kata**

---


"""

import matplotlib.pyplot as plt
from collections import Counter

text = " ".join(data["full_text"])

tokens = text.split()
word_counts = Counter(tokens)

top_words = word_counts.most_common(10)
word, count = zip(*top_words)


colors = plt.cm.Paired(range(len(word)))

plt.figure(figsize=(10, 6))
bars = plt.bar(word, count, color=colors)
plt.xlabel("Kata")
plt.ylabel("Frekuensi")
plt.title("Kata-Kata yang Sering Muncul")
plt.xticks(rotation=45)

for bar, num in zip(bars, count):
    plt.text(bar.get_x() + bar.get_width() / 2 - 0.1, num + 1, str(num), fontsize=12, color='black', ha='center')

plt.show()

"""# ***PRE-PROCESING DATA***

**Silahkan masukan dataset ke dalam dataframe. DataFrame adalah menyimpan dan mengelola data dalam bentuk tabel yang terorganisir**
"""

df  = pd.DataFrame(data[['full_text']])
df.head(1000)

"""**CLEANING**

---


"""

import re
import string
import nltk

def remove_URL(tweet):
    url = re.compile(r'https?://\S+|www\.\S+')
    return url.sub(r'', tweet)

def remove_html(tweet):
    html = re.compile(r'<.*?>')
    return html.sub(r'', tweet)

def remove_emoji(tweet):
    emoji_pattern = re.compile("["
        u"\U0001F600-\U0001F64F"
        u"\U0001F300-\U0001F5FF"
        u"\U0001F680-\U0001F6FF"
        u"\U0001F1E0-\U0001F1FF"
                           "]+", flags=re.UNICODE)
    return emoji_pattern.sub(r'', tweet)

def remove_angka(tweet):
    tweet = re.sub('[0-9]+', '', tweet)

    tweet = re.sub(r'\$\w*', '', tweet)

    tweet = re.sub(r'^RT[\s]+', '', tweet)

    tweet = re.sub(r'#', '', tweet)
    return tweet

def remove_punct(tweets):
    translator = str.maketrans('', '', string.punctuation)
    return tweets.translate(translator)

df['cleasing'] = df['full_text'].apply(lambda x: remove_URL(x))
df['cleasing'] = df['cleasing'].apply(lambda x: remove_html(x))
df['cleasing'] = df['cleasing'].apply(lambda x: remove_emoji(x))
df['cleasing'] = df['cleasing'].apply(lambda x: remove_punct(x))
df['cleasing'] = df['cleasing'].apply(lambda x: remove_angka(x))

df.head(411)

"""**CASE FOLDING AND TOKENIZATION**"""

df['Tokenization and Case Folding'] = df['cleasing'].apply(lambda x: x.lower().split())
df.head(411)

"""***FILTERING ATAU STOPWORD REMOVAL***"""

from nltk.corpus import stopwords
nltk.download('stopwords')
stop_words = stopwords.words('indonesian')

def remove_stopwords(text):
    return [word for word in text if word not in stop_words]

df['Filtering/stopword removal'] = df['Tokenization and Case Folding'].apply(lambda x: remove_stopwords(x))
df.head(411)

"""***STEAMMING DATA***"""

!pip install Sastrawi

from Sastrawi.Stemmer.StemmerFactory import StemmerFactory
from nltk.stem import PorterStemmer
from nltk.stem.snowball import SnowballStemmer

factory = StemmerFactory()
stemmer = factory.create_stemmer()

def stem_text(text):
    return [stemmer.stem(word) for word in text]

df['stemming_data'] = df['Filtering/stopword removal'].apply(lambda x: ' '.join(stem_text(x)))
df.head(411)

"""***DROP DATA DUPLICATES***"""

df.drop_duplicates(subset ="stemming_data", keep = 'first', inplace = True)
df.head(411)

"""# ***SAVE DATASET HASIL PRE-PROCESSING DATA***"""

df.to_csv('Hasil_Preprocessing_Data.csv',encoding='utf8', index=False)

"""# ***VIS ORIGINAL DATA WORDCLOUD & FREKUENSI KATA***

**WORDCLOUD**

---
"""

data = pd.read_csv("Hasil_Preprocessing_Data.csv")
data.info()

import pandas as pd
import numpy as np
from PIL import Image
from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator
import matplotlib.pyplot as plt

df = ' '.join(data['stemming_data'].tolist())

stopwords = set(STOPWORDS)
stopwords.update(['https', 'co', 'RT', '...', 'amp'])

wc = WordCloud(stopwords=stopwords, background_color="black", max_words=500, width=800, height=400)
wc.generate(df)

plt.figure(figsize=(10, 5))
plt.imshow(wc, interpolation='bilinear')
plt.axis("off")
plt.show()

"""**FREKUENSI KATA**

---


"""

import matplotlib.pyplot as plt
from collections import Counter

text = " ".join(data["stemming_data"])

tokens = text.split()
word_counts = Counter(tokens)

top_words = word_counts.most_common(10)

word, count = zip(*top_words)

# Definisikan palet warna
colors = plt.cm.Paired(range(len(word)))

plt.figure(figsize=(10, 6))
bars = plt.bar(word, count, color=colors)
plt.xlabel("Kata")
plt.ylabel("Frekuensi")
plt.title("Kata-Kata yang Sering Muncul")
plt.xticks(rotation=45)

# Menambahkan angka rata tengah di atas setiap bar
for bar, num in zip(bars, count):
    plt.text(bar.get_x() + bar.get_width() / 2 - 0.1, num + 1, str(num), fontsize=12, color='black', ha='center')

plt.show()